# 老一套

## 1. 编译篇

### 1.1. 编译阶段做什么？链接阶段做什么？

编译过程：将预处理完的文件进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。

汇编过程：将汇编代码转变成机器可以执行的指令。

经过 `预处理`、`编译`、`汇编`三个过程（一起叫做**编译阶段**），C源代码文件才生了**目标文件**。

**链接阶段**：把各个模块之间的相互引用的部分都处理好，使得各个模块之间能够正确地衔接起来形成可执行文件。这个过程主要包括：**地址和空间分配、符号决议、重定位**。

### 1.2. 动态链接和静态链接的区别

静态链接：**生成可执行文件之前就完成了所有链接；可执行文件大；空间浪费（存在多个副本）；更新困难；**

动态链接：**程序执行才进行链接；可执行文件小；节约内存（共享一个副本）；牺牲少部分性能；只需更新库即可；**

动态链接出现的原因就是为了解决静态链接的两个问题：空间浪费、更新困难。

### 1.3. 目标文件中有什么？

可执行文件、目标文件、链接库，他们使用对应的格式存储：

- Windows下 PE（Portable Executable）
- Linux下 ELF（Executable Linkable Format）

以ELF格式为例，目标文件里面内容：

- ELF Header
- 代码段（.text）
- 数据段（.data）：存放**已经初始化**的全局变量和局部静态变量。
- 只读数据段（.rodata）：比如常量。
- bss段（.bss）：存放**未初始化**的全局变量和局部静态变量。
- 其他段：.init、.debug、.comment、.symtab等
- 段表（Section Header Table）：描述所有段的信息：段名、段长度、偏移、读写权限、其他属性。

## 2. 操作系统篇

### 2.1. malloc原理

glibc中实现：

- size小于 128 KB，则通过 brk() 申请内存；（free时，先缓存在 malloc 的内存池）
- size大于 128 KB，则通过 mmap() 申请内存；（free时，归还给操作系统）

为什么要这么设计？

- brk直接在堆上分配内存，调整brk指针即可，实现简单。但容易形成碎片，需要等待高地址内存释放了才能释放。借助内存池的使用可以减少缺页中断，大大降低CPU消耗。
- mmap在进程内存映射段找一段空闲的虚拟内存，第一次使用产生缺页中断，CPU消耗大。

【为什么free知道释放多大的内存？】

![free](images/0/free.png)

### 2.2. fork和vfork区别

- **fork()**：
	- 子进程拷贝父进程的物理页表；（**写时拷贝**（copy-on-write））
	- 父子进程执行次序不确定；
- **vfork()**：
	- 子进程与父进程共享物理页表；
	- 保证子进程先运行，在调用exec或exit后，唤醒父进程。

使用fork函数得到的子进程从父进程的**继承了整个进程的地址空间**，包括：<u>进程上下文、进程堆栈、内存信息、打开的文件描述符、信号控制设置、进程优先级、进程组号、当前工作目录、根目录、资源限制、控制终端等</u>。

子进程与父进程的区别在于：

1. **父进程设置的锁，子进程不继承**（因为如果是排它锁，被继承的话，矛盾了）
2. **各自的进程ID和父进程ID不同**
3. **子进程的未决告警被清除**；
4. **子进程的未决信号集设置为空集**。

### 2.3. I/O多路复用（select/poll/epoll）

问题：单机**理论**最大能支持多少TCP连接？

根据四元组，最大TCP连接数 = 客户端IP数(2^32) * 客户端port数(2^16)

实际情况下（比如，要支持C10K），受几个方面限制：

- **文件描述符**：ulimit可以改变数目；
- **系统内存**：每个TCP连接都有对应的数据结构，会占用一定的内存。
- **网络 I/O 模型**：单纯使用进程或线程来提高并发，系统也是扛不住的。就要考虑**I/O多路复用**技术。

#### 2.3.1. select

将已连接的 Socket 都放到一个 **文件描述符集合** ，然后调用 **select** 函数将文件描述符集合 **拷贝到内核** 里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过 **遍历** 文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合 **拷贝回用户态** 里，然后用户态还需要再通过 **遍历** 的方法找到可读或可写的 Socket，然后再对其处理。

分析：

- 每调用一次select，需进行 **2 次 遍历** 文件描述符集合；
- 每调用一次select，需进行 **2 次 拷贝** 文件描述符集合；
- select 使用固定长度的 BitsMap，表示文件描述符集合，由内核中的 FD_SETSIZE 限制，** 默认最大值为 1024**。

#### 2.3.2. poll

**poll** 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，**突破了 select 的文件描述符个数限制**，当然还会受到**系统文件描述符限制**。

#### 2.3.3. epoll

```c
int epoll_fd = epoll_create1(0);

epoll_ctl(epoll_fd, EPOLL_CTL_ADD, ...);
...
epoll_ctl(epoll_fd, EPOLL_CTL_ADD, ...);

while (1) {
	epoll_wait(epoll_fd, ...);
}
```

epoll通过两个方面，很好的解决了select/poll的问题：

- epoll 在内核里**使用红黑树来跟踪进程所有待检测的文件描述符**；
	- epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，**减少了内核和用户空间大量的数据拷贝和内存分配**。
- epoll 使用**事件驱动**的机制，内核里维护了一个链表来记录就绪事件。
	- 当用户调用 epoll_wait() 函数时，**只会返回有事件发生的文件描述符的个数**，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

![epoll](images/0/epoll.png)

分析：

- 整个流程，**只需要拷贝一次文件描述符** 到内核。
- 每次epoll_wait() ，**只返回有事件发生的文件描述符个数**。不需要轮询所有文件描述符。
- 存在**系统文件描述符限制**。

epoll支持两种触发模式，默认是水平触发：

- **边缘触发（edge-triggered，ET）**：当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**。（不管进程有没有调用read去读）
- **水平触发（level-triggered，LT）**：当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**。

### 2.4. 死锁条件和避免

死锁条件：

- **互斥条件**：指多个线程不能同时使用同一个资源；
- **持有并等待条件**：持有了A资源，还想要B资源；
- **不可剥夺条件**：使用完之前不能被其他线程获取；
- **环路等待条件**：两个线程获取资源的顺序构成了环形链；

避免死锁：

只需要破环其中一个条件就可以，比如使用**资源有序分配法**，来破坏环路等待条件。

### 2.5. 进程和线程的区别

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；

相比进程，线程能**减少开销**，体现在：

- **线程的创建时间比进程快**，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是**共享**它们；
- **线程的终止时间比进程快**，因为线程释放的资源相比进程少很多；
- **<u>同一个进程内的线程切换</u> 比 <u>进程切换</u> 快**，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
- 由于同一进程的各线程间共享内存和文件资源，那么**线程之间的数据传递效率更高**；

### 2.6. 进程间通信有哪些方式？

- **管道**：pipe()
- **消息队列**：msgget()/msgsnd()/msgrcv()/msgctl()
	- 消息队列不适合大数据的传输。内核有限制：MSGMAX、MSGMNB。
	- 消息队列通信过程中，存在**用户态与内核态之间的数据拷贝**开销。
- **共享内存**：shmget()/shmat()/shmdt()
	- 共享内存的机制，就是**拿出一块虚拟地址空间来，映射到相同的物理内存中**。
	- 就不存在数据拷贝的开销了。但引入了新问题：同时写会冲突。可以使用**信号量**来实现进程间的互斥与同步。
- **信号**：signal()/kill()
	- IPC中唯一的异步通信机制。
	- 信号处理：执行默认操作；捕捉信号；忽略信号。
- **socket**：socket()
	- 类型SOCK_STREAM/SOCK_DGRAM；

### 2.7. 页面置换算法

**交换机制**：当物理内存接近满的时候，操作系统为了使整个系统仍然可用，会将一部分不常使用的页面移到磁盘上，为更经常使用的页面腾出空间。

**页面置换算法**的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**。

出现过哪些页面置换算法：

- **FIFO**：维护一个队列，每次直接清理队列头的页面。几乎无性能开销，但是效果不好。
- **Second Chance FIFO**：维护一个循环队列，每次清理访问标志位为0的页面，每次访问后将标志位置为1，这样只要周期内页面有访问，就会免遭清理，除非所有的页都为1。由于使用循环队列，内存操作较多，故一般使用下面一个算法。
- **时钟算法**：指针和环形链表/队列实现SCFIFO，消除了内存操作，也是较为常用的算法，效果较好，比较NRU有较大改善。
	- 把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
- **LRU（最近最久未使用）算法**：在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。开销比较大。
- **LFU（最不常用）算法**：使用的频度Freq由系统时钟中断处理程序统计，效果较好，但是有一定的性能开销，且没有实现“最近”。
	- 要增加一个计数器来实现，这个硬件成本是比较高的。
	- LFU 算法只考虑了频率问题，没考虑时间的问题。
- **老化算法**：在LFU基础上加入频度老化，实现了“最近”，越久的使用次数权重越低。

Linux内核现在使用的页面置换算法是**两级的软件LRU**，也就是分为active和inactive类型的两个链表，并实现软件LRU算法。

两级LRU存在的问题：

- 算法CPU开销太大，而且经常做出错误的决策。
- Active/Inactive这两种分类，是一个相当粗的粒度。经常会看到页表在两个表中来回移动。

Linux 6.2引入了多级LRU：

- 借鉴了老化算法的思路，按照页面的生成（分配）时间将LRU表分为若干Generation。
- 在LRU页面扫面的时候，使用增量的方式扫描，根据周期内访问过的页面对页表进行扫描，除非这段时间内访问的内存分布非常稀疏，通常页表相对于倒排页表有更好的局部性，进而可以提升CPU的缓存命中率。

## 3. 网络篇

## 4. 内核篇

### 4.1. linux启动做了哪些事情

可以分为三个阶段：

- **1. BIOS引导**
	- BIOS是如何启动的，CPU硬件逻辑设计为在加电瞬间强行将CS值置为0XF000，IP为0XFFF0，这样CS:IP就指向0XFFFF0这个位置，这个位置正是BIOS程序的入口地址。
	- BIOS的第一步动作就是进行**上电自检（POST）**。POST的工作是检查硬件设备。随着BIOS程序的执行，屏幕上会显示显卡的信息，内存的信息等。
	- BIOS的第二步动作：**BIOS在内存中建立中断向量表和中断服务程序**。
	- BIOS的**runtime服务** 搜索**可引导启动的设备**，**寻找MBR**。一个软驱，一台光驱，一个硬盘上的分区，网络上的设备甚至一个usb 闪存盘都可以作为一个启动设备。linux通常是从硬盘启动的。硬盘上的MBR（主启动记录）包含有基本的boot loader。
- **2. GRUB引导**
	- 位于**MBR中的主boot loader**是一个512字节的镜像，包含了bootload程序代码，和一个小的分区表。主boot loader的工作是**寻找并加载次boot loader（内核加载程序）**。
	- 在次boot loader存在与内存中后，就可以对文件系统进行查询了，同时将默认的内核镜像以及初始化内存盘镜像也被加载到内存中。
- **3. 内核引导**
	- 解压bzImage，从head.S的start汇编例程开始执行。
	- 进入保护模式，设置中断描述符表和全局描述符表，创建内存分页机制。
	- start_kernel启动内核，设备驱动程序的加载，创建init进程。

![start](images/0/start.png)

【initrd（bootloader initialized RAM disk）】：

一部分驱动程序直接被编译进内核镜像中，另一部分驱动程序则是以模块的形式放在initrd(ramdisk)中。早期内核版本，boot loader 会将存储介质中的 initrd 文件加载到内存，内核便去执行initrd中的init脚本，这时内核将控制权交给了init文件处理，其中init脚本也主要是加载各种存储介质相关的设备驱动程序。当所需的驱动程序加载完后，会创建一个根设备，然后将根文件系统rootfs以只读的方式挂载。这一步结束后，释放未使用的内存，转换到真正的根文件系统上面去，同时运行/sbin/init程序。

### 4.2. 内核分配内存函数和区别

【页为单位】

如果想要 **以页为单位的连续物理页**，使用 **`alloc_pages()`**。

【对象为单位】

slub分配器：**`kmem_cache_alloc()`**

【字节为单位】
通常**以字节为单位**的分配：

- **`kmalloc()`** 确保页在**物理地址上是连续的**（虚拟地址自然也是连续的）。用于申请较小的，连续的物理内存。
	- CONFIG_SLUB情况下：kmalloc在启动的时候会预先创建一些不同大小的slab，会寻找大小刚好合适的slab来分配内存。如果过大，也会使用alloc_pages()来分配内存。
- **`vmalloc()`** 分配的内存虚拟地址是连续的，而**物理地址则无须连续**。用于申请较大的内存，虚拟内存是连续的。分配的内存在VMALLOC_START~VMALLOC_END之间。
	- 从VMALLOC_START~VMALLOC_END，查找空闲的虚拟地址空间，根据size，调用alloc_page()依次分配单个页面，然后映射到找到的连续虚拟地址空间。

### 4.3. 内核同步机制

- **原子操作**：atomic_set、atomic64_set、set_bit（原子位）
- **自旋锁**：持有自旋锁不允许睡眠。
	- spin_lock：获取自旋锁；
	- spin_lock_irq：禁止本地中断，并获取锁；
	- spin_lock_irqsave：保存本地中断状态，禁止本地中断，并获取锁；
	- spin_lock_bh：禁止下半部执行（软中断），并获取锁；
- **读写锁**：读锁被持有时，读者可以继续占用锁，写者要等待所有读者释放锁才能占用。
- **信号量**：一种**睡眠锁**。如果信号量不可用，它将把调用进程置成TASK_INTERRUPTIBLE状态，进入睡眠。
	- 又分：计数信号量、互斥信号量、读写信号量；
- **完成变量**：代替信号量的一种简单方法。
	- wait_for_completion：等待指定的完成变量接收信号；
	- complete：发信号唤醒任何等待的任务；
	- 使用案例：子进程执行或退出时，vfork()系统调用使用完成变量唤醒父进程。
- **~~BKL大内核锁~~**：被移除了。
- **顺序锁**：seq锁，写优先于读，使用案例：**jiffies**。
- **内存屏障**：memory barrier。解决处理器和编译器重排序问题。
	- rmb()、wmb()、barrier()
- **RCU锁**：Read-Copy-Update

优先级：**`中断 > 软中断 > 进程上下文`**；

所以：中断可以抢占软中断，软中断可以抢占进程上下文。

### 4.4. 抢占、中断、锁

调度分两种：抢占式调度、非抢占式调度。**Linux使用的是抢占式调度**。

【**抢占**】分两种：

- **用户抢占**：指内核返回用户空间而做出的抢占。比如：从系统调用返回；从中断返回。
- **内核抢占**：指在内核代码的执行过程中发生的抢占。下面可能发生内核抢占：
	- 中断处理结束并返回内核空间之前；
	- preempt_count从非零变成零；
	- 内核代码显示调用schedule()；
	- 任务在内核中阻塞，触发schedule()；

【**中断**】

内核需要管理硬件，但处理器速度比硬件快很多个级别，不能让处理器等待硬件响应，所以需要一种方式使得**硬件能够通知内核**，让内核响应硬件的请求。

两种方式：

- 轮询：定期检查硬件，开销太大。
- **中断**：<u>让硬件有需要时，给内核发送信号。</u>

【**锁**】

内核抢占发生的条件：**任务不能持有锁**。

通过控制preempt_count，为 0 表示允许抢占，不为 0 表示禁止抢占。

```c
// 关闭抢占
#define preempt_disable() \
do { \
	preempt_count_inc(); \
	barrier(); \
} while (0)
```

### 4.5. 进程上下文和中断上下文

**进程上下文**是一种内核所处的操作模式，此时内核代表进程执行。（例如：执行系统调用或运行内核线程）。进程可以睡眠，也可以调用程序。

一般程序在用户空间执行。当一个程序执行了系统调用或者触发了某个异常，它就陷入了内核空间。此时，我们称**内核“代表进程执行”并处于进程上下文**。

**中断上下文**没有后备进程，不可以睡眠（否则又怎能再对它重新调用呢？）。且具有较严格的时间限制。

### 4.6. 中断栈

中断处理程序（上半部，top half）拥有了自己的栈，每个处理器一个，大小为一页。这个栈就称为**中断栈**。

### 4.7. 为什么需要下半部（bottom half）？

简单说：又想中断处理程序运行的快，又想中断处理程序完成的工作量多。只能把一些工作放到以后去做。

**上半部分简单快速，执行的时候禁止一些或全部中断。下半部分稍后执行，而且执行期间可以响应所有的中断。**

下半部有哪些实现：

- **软中断**
- **tasklet**：基于软中断实现；
- **工作队列**：基于内核线程实现；

### 4.8. 系统调用

用户空间程序无法直接执行内核代码。以**某种方式通知**（这种方式是**软中断**）内核，需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序在内核空间执行系统调用。

**陷入内核时，把参数从用户空间传给内核，参数放在寄存器里。返回值也通过寄存器传递。**

**内核在执行系统调用时，处于进程上下文。**

**在进程上下文中，内核可以休眠，可以被抢占。**

### 4.9. 发生异常时，CPU会做什么？

发生异常时，CPU需要先记录当前程序的上下文，然后再去处理异常，异常处理完成后返回到原先的程序当中。

#### 4.9.1. 异常

【异常定义】：

- **异常**：由于 内部或者外部的一些事件 , 导致 处理器停下正在处理的工作, 转而去处理这些发生的事；
- **处理器状态**：当遇到异常的时候，**先将处理器状态保存起来**, 以便执行完异常处理程序后, 可以恢复处理器状态, 继续执行异常出现点下面的代码；
- **异常出现**：在**一个时间点 可以出现 多个异常**；
- **异常向量**：当异常发生的时候, 程序被强行**从一个固定的内存地址执行, 每个种类的异常都有对应的一固定内存地址**, 这个内存地址就是异常向量 ；

【异常类型】：

ARM架构下支持 7 种异常：

- **Reset**：处理器在工作时, 突然 **按下重启键, 就会触发该异常**;
- **Undefined instructions**：处理器**无法识别指令**的异常；
- **Software interrupt (SWI)**：**软中断**, 软件中需要去打断处理器工作, 可以使用软中断来执行；
- **Prefetch Abort (instruction fetch memory abort)**：**预取指令失败**, ARM 在执行指令的过程中, 要先去预取指令准备执行, 如果预取指令失败, 就会产生该异常；
- **Data Abort (data access memory abort)**：读取数据失败；
- **IRQ (interrupt)**：**普通中断**；
- **FIQ (fast interrupt)**：**快速中断**，比IRQ响应快；

【异常处理】：

异常发生时, ARM 处理器会跳转到对应该异常的 **固定地址** 去执行异常处理程序。这个 固定的地址 就是**异常向量**。

**每个异常类型对应两个异常向量**, 默认是 Normal address。

![exception](images/0/exception.png)

## 5. 文件系统篇

## 6. 命令篇

### 6.1. 查看进程缺页中断信息

```bash
ps -o majflt,minflt -p <pid>
```

## 参考

https://blog.csdn.net/shulianghan/article/details/80163777

https://blog.csdn.net/chen_geng/article/details/51718747

https://developer.aliyun.com/article/47675

https://blog.eastonman.com/blog/2021/04/linux-multi-lru/

https://lwn.net/Articles/851184/